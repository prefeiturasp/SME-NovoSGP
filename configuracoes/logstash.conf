input {
  rabbitmq {
    subscription_retry_interval_seconds => 2
    automatic_recovery => true
    connect_retry_interval => 3
    durable => true   
    exchange => "EnterpriseApplicationLog" 
    exchange_type => "direct"
    key => ""
    host => "rabbitmq"
    vhost => "logs"
    queue => "ApplicationLog"
    port => 5672	
    user => "${RABBITMQ_DEFAULT_USER}"
    password => "${RABBITMQ_DEFAULT_PASS}"    
    passive => false
    prefetch_count => 10
    threads => 1
    ack => true
    # type => "Log"
  }  
}

output {
  elasticsearch {
    action => "index"
    codec => "json"
    # flush_size => ... # number (optional), default: 5000
	# idle_flush_time => ... # number (optional), default: 1
	
    hosts => ["http://elastic:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    user => 'elastic'
    password => "SGP123"
    # index_type => ... # string (optional)
    # manage_template => ... # boolean (optional), default: true
    # node_name => ... # string (optional)
    # port => ... # string (optional)
    # protocol => ... # string, one of ["node", "transport", "http"] (optional)
    # template => ... # a valid filesystem path (optional)
    # template_name => ... # string (optional), default: "logstash"
    # template_overwrite => ... # boolean (optional), default: false
    # workers => 2
  }
}
